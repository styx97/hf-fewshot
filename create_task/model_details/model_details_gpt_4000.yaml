# This version permits up to 4000 tokens in the response
model_details:
    model_name: gpt-4-turbo
    model_family: gpt
    scores: False
    batch_size: 8
    max_new_tokens: 4000
    temperature: 0.01

